"story_id","epic","title","user_role","description","business_value","priority","story_points","dependencies","acceptance_criteria","technical_tasks","definition_of_done"
"VCS-001","Service Foundation and DevOps","Establish Service Foundation and Database Connectivity","Platform Engineer","As a Platform Engineer, I want to initialize the NestJS microservice with a structured project layout, including database connectivity, centralized logging, and global error handling, so that developers have a stable, observable, and maintainable foundation to build features upon.","Accelerates development by providing a standardized and ready-to-use service foundation. Improves maintainability and reduces debugging time through structured logging and consistent error handling.","Must Have","5","[]","[{""scenario"":""Service starts and connects to the database"",""given"":""the correct PostgreSQL connection details are provided in the environment variables"",""when"":""the application is started"",""then"":""the service successfully connects to the database without errors and is ready to accept requests.""},{""scenario"":""Logs are output in structured JSON format"",""given"":""the application is running"",""when"":""any log message is generated by the application"",""then"":""the log output to stdout is a single line of valid JSON containing a timestamp, level, correlation ID, and message.""},{""scenario"":""Unhandled exceptions are caught and formatted correctly"",""given"":""an API request triggers an unexpected server-side error"",""when"":""the global exception filter processes the error"",""then"":""the client receives a generic HTTP 500 response with a standardized JSON error structure, and the full error stack trace is logged in JSON format.""},{""scenario"":""DTO validation errors are formatted correctly"",""given"":""an API request is made with an invalid data payload (e.g., a missing required field)"",""when"":""the global validation pipe processes the request"",""then"":""the client receives an HTTP 400 response with a structured JSON body detailing the specific validation errors.""}]","[""Initialize NestJS project using the CLI."",""Configure TypeORM for PostgreSQL using environment variables."",""Implement a custom LoggerService for structured JSON logging."",""Create a global HttpExceptionFilter for standardized error responses."",""Enable a global ValidationPipe in main.ts.""]","[""Application successfully connects to a local and cloud PostgreSQL database."",""All logs are confirmed to be in structured JSON format."",""Unit tests for the exception filter and logger service are written and passing."",""Code is peer-reviewed and merged into the main branch.""]"
"VCS-002","Service Foundation and DevOps","Containerize the Service and Automate CI/CD","DevOps Engineer","As a DevOps Engineer, I want to containerize the microservice using Docker and create an automated CI/CD pipeline in GitHub Actions, so that every code change is automatically tested, built, and deployed, ensuring rapid, reliable, and consistent releases.","Increases development velocity and reduces the risk of human error in deployments. Enforces quality gates (linting, testing) on all code changes, improving overall system stability and reliability.","Must Have","8","[""VCS-001""]","[{""scenario"":""Application is successfully built into a Docker image"",""given"":""the source code is available"",""when"":""the `docker build` command is executed using the multi-stage Dockerfile"",""then"":""a production-optimized Docker image is created successfully and can be run locally.""},{""scenario"":""CI pipeline triggers and passes on a pull request"",""given"":""a developer opens a new pull request"",""when"":""the GitHub Actions CI workflow is triggered"",""then"":""the pipeline must run linting checks and all unit/integration tests, and the build must fail if any step fails.""},{""scenario"":""CD pipeline deploys to staging on merge to main"",""given"":""a pull request is successfully merged into the main branch"",""when"":""the GitHub Actions CD workflow is triggered"",""then"":""the pipeline must build the Docker image, push it to AWS ECR with a unique tag, and trigger a Terraform deployment to update the service in the staging AWS EKS cluster.""},{""scenario"":""Docker image is scanned for vulnerabilities"",""given"":""a new Docker image has been built in the CI pipeline"",""when"":""the security scan step is executed"",""then"":""the image is scanned for known vulnerabilities, and the build fails if critical vulnerabilities are found.""}]","[""Create a multi-stage Dockerfile for production builds."",""Create a `.dockerignore` file to exclude unnecessary files."",""Configure a GitHub Actions workflow YAML file for CI (lint, test)."",""Configure the workflow for CD (build, push to ECR, invoke Terraform)."",""Set up GitHub OIDC for secure, keyless authentication to AWS.""]","[""The Docker image is successfully built and runs."",""The CI pipeline passes for all pull requests."",""The CD pipeline successfully deploys the service to the staging environment upon a merge to main."",""All quality and security gates in the pipeline are functional.""]"
"VCS-003","Vendor Profile and Store Management","Vendor Manages Store Profile Information","Vendor","As a Vendor, I want to view and edit my store's profile information, including its name, address, and contact details, so that I can ensure customers and riders have accurate information for my business.","Ensures data accuracy for logistics (rider navigation), customer experience (correct store info), and communication, which builds trust and reduces operational errors.","Must Have","5","[""VCS-001""]","[{""scenario"":""Vendor successfully fetches their profile"",""given"":""I am an authenticated vendor"",""when"":""I make a GET request to `/api/v1/vendors/me`"",""then"":""the system returns my complete vendor profile information.""},{""scenario"":""Vendor successfully updates their profile"",""given"":""I am an authenticated vendor"",""when"":""I send a PATCH request to `/api/v1/vendors/me` with valid updated data"",""then"":""the system saves the changes to my profile and returns the updated profile."",""and"":""the update action is logged in the audit trail.""},{""scenario"":""Vendor cannot update another vendor's profile"",""given"":""I am authenticated as Vendor A"",""when"":""I attempt to send a PATCH request to the endpoint for Vendor B's profile"",""then"":""the system rejects the request with a 403 Forbidden error.""},{""scenario"":""System rejects profile update with invalid data"",""given"":""I am an authenticated vendor"",""when"":""I send a PATCH request with invalid data (e.g., an empty store name)"",""then"":""the system rejects the request with a 400 Bad Request error and a descriptive validation message.""}]","[""Create TypeORM entities for VendorProfile."",""Generate and apply database migration for the new tables."",""Implement a VendorController with GET and PATCH endpoints."",""Implement VendorService with business logic for fetching and updating profiles."",""Create DTOs with class-validator decorators for the update payload."",""Apply JWT and RBAC guards to the controller endpoints.""]","[""All API endpoints are implemented and documented in Swagger/OpenAPI."",""Integration tests cover all success and failure scenarios for the endpoints."",""Security requirements (RBAC) are fully implemented and tested."",""Code is peer-reviewed and meets the 80% test coverage requirement.""]"
"VCS-004","Vendor Profile and Store Management","Vendor Sets and Manages Daily Business Hours","Vendor","As a vendor, I want to define and manage my store's daily operating hours, so that the platform automatically controls my store's availability and prevents customers from placing orders outside of my business hours.","Automates store availability, preventing unfulfillable orders placed after hours. This improves operational efficiency for vendors and manages customer expectations, enhancing platform reliability.","Must Have","5","[""VCS-003""]","[{""scenario"":""Vendor successfully sets business hours for multiple days"",""given"":""I am an authenticated vendor"",""when"":""I send a request to update my business hours with a valid schedule for several days"",""then"":""the system saves the hours for each day, and subsequent requests to fetch my profile include the correct hours.""},{""scenario"":""System rejects invalid time ranges"",""given"":""I am an authenticated vendor"",""when"":""I attempt to set a schedule where the closing time is before the opening time for a given day"",""then"":""the system rejects the request with a 400 Bad Request error and a clear validation message.""},{""scenario"":""Vendor marks a day as closed"",""given"":""I am an authenticated vendor"",""when"":""I send a request to update my business hours, marking Sunday as closed"",""then"":""the system saves this status, and my profile reflects that the store is closed on Sundays.""}]","[""Create TypeORM entity for VendorBusinessHour with a relationship to VendorProfile."",""Generate and apply the database migration."",""Extend the VendorController and VendorService to handle CRUD operations for business hours."",""Create a DTO for business hours with custom validation to check that end time is after start time."",""Update the GET profile endpoint to join and return the business hours.""]","[""API endpoints for managing business hours are implemented and tested."",""Custom validation logic for time ranges is covered by unit tests."",""The vendor profile fetch endpoint correctly returns the associated hours."",""Code is peer-reviewed and merged.""]"
"VCS-005","Vendor Profile and Store Management","Vendor Toggles Store Availability (Online/Offline)","Vendor","As a Vendor, I want a master switch to immediately toggle my store's availability between 'Online' and 'Offline' so that I can instantly stop or resume accepting new orders to manage unexpected events.","Provides vendors with direct control over their operational status, preventing orders during unforeseen closures. This reduces order cancellations and improves customer satisfaction.","Must Have","3","[""VCS-003""]","[{""scenario"":""Vendor successfully toggles store to 'Offline'"",""given"":""I am an authenticated vendor and my store is 'Online'"",""when"":""I send a PATCH request to `/api/v1/vendors/me/availability` with the status 'Offline'"",""then"":""the system updates my store's status to 'Offline' and publishes a `VendorStatusChanged` event to the SNS topic.""},{""scenario"":""Vendor successfully toggles store to 'Online'"",""given"":""I am an authenticated vendor and my store is 'Offline'"",""when"":""I send a PATCH request to `/api/v1/vendors/me/availability` with the status 'Online'"",""then"":""the system updates my store's status to 'Online' and publishes a `VendorStatusChanged` event.""},{""scenario"":""Event payload is correct"",""given"":""a vendor has changed their availability status"",""when"":""the `VendorStatusChanged` event is published"",""then"":""the event payload must be a JSON object containing the `vendorId` and the new `status`.""}]","[""Add an `isOnline` boolean field to the VendorProfile entity and create a migration."",""Create a new endpoint in VendorController for the availability toggle."",""Implement the logic in VendorService to update the status."",""Integrate the AWS SDK for SNS to publish the event after a successful database update."",""Use the Transactional Outbox pattern to ensure the event is published reliably.""]","[""The API endpoint is implemented and tested."",""An integration test verifies that the SNS event is published with the correct payload upon status change."",""The endpoint is secured and documented."",""Code is peer-reviewed and merged.""]"
"VCS-006","Vendor Profile and Store Management","Vendor Manages Business License Information","Vendor","As a vendor, I want to add, view, and update my business license details, such as FSSAI number and expiry date, so that I can maintain compliance with platform policies and legal regulations.","Ensures the platform operates with legally compliant vendors, mitigating legal risk. Enables automated compliance checks and reminders.","Must Have","3","[""VCS-003""]","[{""scenario"":""Vendor adds a new license"",""given"":""I am an authenticated vendor"",""when"":""I send a POST request to `/api/v1/vendors/me/licenses` with valid license details"",""then"":""a new license record is created and associated with my profile.""},{""scenario"":""Vendor updates an existing license"",""given"":""I am an authenticated vendor and have an existing license"",""when"":""I send a PATCH request to `/api/v1/vendors/me/licenses/{licenseId}` with a new expiry date"",""then"":""the system updates the expiry date for that specific license.""},{""scenario"":""System rejects a license with a past expiry date"",""given"":""I am an authenticated vendor"",""when"":""I attempt to add or update a license with an expiry date in the past"",""then"":""the system rejects the request with a 400 Bad Request error.""}]","[""Create TypeORM entity for VendorLicense with a relationship to VendorProfile."",""Generate and apply the database migration."",""Create a new LicenseController for managing licenses scoped to the authenticated vendor."",""Implement LicenseService with CRUD logic and validation."",""Create DTOs for license creation and updates.""]","[""All CRUD API endpoints for licenses are implemented and tested."",""Validation for future expiry dates is working correctly."",""Endpoints are secured to ensure vendors can only manage their own licenses."",""Code is peer-reviewed and merged.""]"
"VCS-007","Product and Catalog Management","Vendor Manages Product Categories","Vendor","As a Vendor, I want to create, view, edit, and delete product categories for my store, so that I can effectively organize my product catalog for customers.","Improves catalog organization for vendors and enhances product discovery for customers, potentially leading to increased sales.","Must Have","3","[""VCS-003""]","[{""scenario"":""Vendor creates a new category"",""given"":""I am an authenticated vendor"",""when"":""I send a POST request to `/api/v1/categories` with a unique category name"",""then"":""a new category is created for my store.""},{""scenario"":""Vendor attempts to create a duplicate category"",""given"":""I am an authenticated vendor and a category named 'Beverages' already exists"",""when"":""I attempt to create another category named 'Beverages'"",""then"":""the system rejects the request with a 409 Conflict error.""},{""scenario"":""Vendor deletes an empty category"",""given"":""I am an authenticated vendor and have a category with no products in it"",""when"":""I send a DELETE request for that category"",""then"":""the category is successfully deleted.""},{""scenario"":""Vendor attempts to delete a category with products"",""given"":""I am an authenticated vendor and have a category with products assigned to it"",""when"":""I attempt to send a DELETE request for that category"",""then"":""the system rejects the request with a 409 Conflict error and a message indicating it cannot be deleted.""}]","[""Create TypeORM entities for ProductCategory and Product, and the corresponding migrations."",""Implement a CategoryController with full CRUD endpoints."",""Implement a CategoryService with business logic, including the duplicate name check and the check for associated products before deletion."",""Apply JWT and RBAC guards to ensure vendors can only manage their own categories.""]","[""All CRUD API endpoints for categories are implemented and tested."",""Business rule validation (uniqueness, deletion constraint) is fully tested."",""Endpoints are secured and documented in OpenAPI."",""Code is peer-reviewed and meets quality standards.""]"
"VCS-008","Product and Catalog Management","Vendor Manages Products (CRUD)","Vendor","As a Vendor, I want to perform full CRUD (Create, Read, Update, Delete) operations on the products in my catalog, so that I can manage my inventory, pricing, and offerings.","Provides the fundamental capability for vendors to manage their sellable items, which is the core of the marketplace functionality.","Must Have","8","[""VCS-007""]","[{""scenario"":""Vendor creates a new product"",""given"":""I am an authenticated vendor and have an existing category"",""when"":""I send a POST request to `/api/v1/products` with valid product data"",""then"":""a new product is created in my catalog and associated with the specified category.""},{""scenario"":""Vendor updates an existing product"",""given"":""I am an authenticated vendor and have an existing product"",""when"":""I send a PATCH request to `/api/v1/products/{productId}` with an updated price"",""then"":""the product's price is updated, and a `ProductStockChanged` event is published.""},{""scenario"":""Vendor deletes a product not in an active order"",""given"":""I am an authenticated vendor and have a product that is not part of any active orders"",""when"":""I send a DELETE request for that product"",""then"":""the product is soft-deleted (marked as inactive) in the database.""},{""scenario"":""Vendor attempts to delete a product that is in an active order"",""given"":""I am an authenticated vendor and have a product that is part of an active order"",""when"":""I attempt to send a DELETE request for that product"",""then"":""the system calls the Order Management service to check, and then rejects the request with a 409 Conflict error.""}]","[""Implement a ProductController with full CRUD endpoints."",""Implement a ProductService with business logic for all CRUD operations."",""Implement the soft-delete pattern using TypeORM's `@DeleteDateColumn`."",""Integrate an HTTP client to call the Order Management service's internal API for the active order check."",""Implement event publishing for product stock/price changes to an SNS topic.""]","[""All CRUD API endpoints for products are implemented and tested."",""Soft-delete and the active-order check before deletion are verified."",""Event publishing on product updates is implemented and tested."",""Endpoints are secured, documented, and peer-reviewed.""]"
"VCS-009","Bulk Data Operations","Vendor Bulk Imports Product Catalog via CSV","Vendor","As a Vendor, I want to bulk import my product catalog using a CSV file so that I can quickly add or update many products at once, saving significant time compared to manual entry.","Dramatically reduces vendor onboarding time and effort for those with large inventories. Improves data accuracy by minimizing manual entry errors.","Should Have","8","[""VCS-008""]","[{""scenario"":""Vendor initiates an import job"",""given"":""I am an authenticated vendor"",""when"":""I request a pre-signed URL, upload a valid CSV to S3, and notify the backend to start processing"",""then"":""a new job is successfully added to the BullMQ queue for processing.""},{""scenario"":""Background job processes a valid CSV file"",""given"":""a valid CSV file has been uploaded and a job is queued"",""when"":""the worker process executes the job"",""then"":""the system parses the CSV, validates all rows successfully, and bulk inserts/updates the products in the database."",""and"":""the job status is marked as 'completed' and the vendor is notified of success.""},{""scenario"":""Background job handles a CSV with some invalid rows"",""given"":""a CSV file with a mix of valid and invalid rows is processed"",""when"":""the worker process executes the job"",""then"":""the system identifies the invalid rows and does not commit any changes to the database (atomic operation)."",""and"":""the job status is marked as 'failed'.""}]","[""Implement an API endpoint to generate a pre-signed S3 PUT URL."",""Integrate BullMQ and configure a queue for CSV import jobs."",""Create a new API endpoint to trigger a job after the file is uploaded."",""Implement a BullMQ worker/processor to handle the job logic."",""In the worker, implement logic to stream the CSV from S3, parse it, and validate each row."",""Implement atomic database operations for bulk insert/update within a transaction.""]","[""The end-to-end flow of uploading a CSV and having it processed by a background job is functional."",""Row-by-row validation is comprehensive."",""The import process is atomic and handles failures correctly."",""The system is tested with large CSV files to ensure memory efficiency."",""Code is peer-reviewed and tested.""]"
"VCS-010","Bulk Data Operations","Vendor Receives Downloadable CSV Import Error Report","Vendor","As a Vendor, I want to receive a downloadable error report that details exactly which rows failed during a CSV import and why, so that I can efficiently correct the data and successfully re-upload my product catalog.","Reduces vendor frustration and support ticket volume by enabling self-service error correction for bulk uploads. Speeds up the vendor onboarding/catalog update process.","Should Have","5","[""VCS-009""]","[{""scenario"":""Error report is generated for a failed import"",""given"":""a CSV import job has failed due to invalid rows"",""when"":""the job processing is complete"",""then"":""a new CSV file is generated containing only the failed rows, with an additional 'Error_Description' column.""},{""scenario"":""Error report is uploaded and a download link is provided"",""given"":""an error report CSV has been generated"",""when"":""the job finalizes its 'failed' state"",""then"":""the report is uploaded to S3, and a secure, time-limited pre-signed GET URL for the report is made available to the vendor."",""and"":""the vendor is notified that the import failed and a report is ready for download.""},{""scenario"":""Error descriptions are clear and accurate"",""given"":""a row in the CSV failed because the price was not a number"",""when"":""the vendor views the error report"",""then"":""the 'Error_Description' for that row clearly states 'Price must be a number'.""}]","[""Extend the BullMQ worker logic from VCS-009."",""Implement logic to collect all failed rows and their specific validation error messages."",""Use a CSV writer library to construct the error report in memory or as a stream."",""Upload the generated report to a 'reports' prefix in the S3 bucket."",""Generate a pre-signed GET URL for the uploaded report."",""Integrate with a notification service (e.g., WebSocket) to inform the user.""]","[""The error report generation is functional and accurate."",""The download link is secure and time-limited."",""The process is tested with various types of row validation errors."",""Code is peer-reviewed and merged.""]"
"VCS-011","Bulk Data Operations","Vendor Bulk Exports Product Catalog to CSV","Vendor","As a vendor, I want to export my entire product catalog to a CSV file, so that I can create a local backup of my data and perform external analysis or bulk updates.","Enhances vendor data portability and control, enabling offline analysis, backups, and a streamlined export-edit-reimport workflow.","Should Have","5","[""VCS-008"",""VCS-009""]","[{""scenario"":""Vendor triggers an export job"",""given"":""I am an authenticated vendor"",""when"":""I send a request to the export endpoint"",""then"":""a new background job is queued to process my catalog export.""},{""scenario"":""Background job generates and uploads the CSV export"",""given"":""an export job is running for my store"",""when"":""the worker process executes the job"",""then"":""it queries all my products, generates a CSV file in the correct format, and uploads it to S3.""},{""scenario"":""Vendor is notified with a download link"",""given"":""my export job has completed successfully"",""when"":""the job status is updated"",""then"":""I receive a notification containing a secure, time-limited download link for my CSV file.""},{""scenario"":""Export handles large catalogs efficiently"",""given"":""my store has over 5,000 products"",""when"":""I trigger an export"",""then"":""the process completes successfully without timing out or running out of memory by using streaming for database reads and CSV writing.""}]","[""Create a new API endpoint to trigger an export job."",""Create a new BullMQ processor for handling export jobs."",""Implement logic in the processor to stream product data from the database using TypeORM's streaming capabilities."",""Use a streaming CSV writer to generate the file."",""Upload the final CSV to S3."",""Notify the user with a pre-signed download link.""]","[""The end-to-end export flow is functional and tested."",""The process is verified to be memory-efficient for large catalogs."",""The exported CSV format is compatible with the import template."",""The download link is secure and time-limited.""]"