[{'id': 'centralized-logging', 'name': 'Centralized Logging', 'type': 'LogAggregation', 'description': 'Aggregates all application and system logs into a central, searchable service. Logs are structured in JSON format to enable effective querying and analysis, and include a correlation ID for tracing requests across microservices.', 'provider': 'AWS CloudWatch Logs', 'features': ['Structured JSON logging (REQ-1-108)', 'Centralized collection from EKS containers', 'Inclusion of a `correlationId` in every log entry (REQ-1-110)', 'Log search and filtering capabilities', 'Configurable log retention and archival policies'], 'configuration': {'LogFormat': 'JSON', 'CorrelationIdField': 'correlationId', 'RetentionPeriod': '90 days in CloudWatch Logs (REQ-1-095)', 'ArchiveDestination': 'AWS S3 Glacier for long-term storage up to 1 year (REQ-1-095)'}}, {'id': 'metrics-collection', 'name': 'Infrastructure & Service Metrics', 'type': 'InfrastructureMonitoring', 'description': 'Collects time-series metrics from all layers of the infrastructure and application services. This provides the raw data for performance monitoring, autoscaling, and alerting.', 'provider': 'Prometheus', 'features': ['Metrics scraping from Kubernetes (EKS) pods and nodes for CPU/memory (REQ-1-109)', 'Collection of AWS managed service metrics (RDS, SQS) via CloudWatch Exporter', 'Scraping custom application metrics exposed via a `/metrics` endpoint (e.g., orders per minute as per REQ-1-093)', 'Monitoring of API latency and error rates (REQ-1-109)', 'Tracking of third-party API success/failure rates (REQ-1-109)', 'Database connection pool monitoring (REQ-1-109)', 'Message queue depth monitoring (REQ-1-109)'], 'configuration': {'ScrapeInterval': '15s', 'StorageRetention': '30d', 'EksIntegration': 'Prometheus Operator with kube-state-metrics', 'AwsIntegration': 'CloudWatch Exporter for Prometheus'}}, {'id': 'distributed-tracing', 'name': 'Distributed Tracing', 'type': 'ApplicationPerformanceMonitoring', 'description': 'Implements end-to-end tracing for requests as they travel across the microservices architecture, enabling latency analysis and service dependency visualization.', 'provider': 'OpenTelemetry', 'features': ['Instrumentation of Node.js (NestJS) services using OpenTelemetry SDKs (REQ-1-108)', 'Automatic context propagation to carry the `correlationId` across services (REQ-1-110)', 'Visualization of request paths and service dependencies', 'Span-level latency analysis to identify performance bottlenecks', 'Trace exporting to a compatible backend for storage and analysis'], 'configuration': {'Instrumentation': 'Automatic for HTTP, gRPC; Manual for custom spans', 'SamplingStrategy': 'Rate-limiting sampler (e.g., 10% of traces + 100% of error traces)', 'TraceExporterBackend': 'AWS X-Ray (recommended for tight AWS integration)'}}, {'id': 'dashboards-and-alerting', 'name': 'Dashboards & Alerting', 'type': 'VisualizationAndAlerting', 'description': 'Provides visualization dashboards for key metrics and a real-time alerting system to notify on-call personnel of system degradation or failures based on predefined rules.', 'provider': 'Grafana & Prometheus Alertmanager', 'features': ['Visualization dashboards for key metrics identified in REQ-1-109 (Grafana)', 'Monitoring of SLA/SLO metrics such as 99.9% uptime and P95 latency (REQ-1-099, REQ-1-093)', 'Real-time alerting on metric thresholds (Prometheus Alertmanager, REQ-1-109)', 'Alert routing to on-call personnel via configurable notification channels (e.g., Slack, PagerDuty)', 'Alert categorization by severity'], 'configuration': {'DataSource': 'Prometheus', 'AlertingRulesPath': 'config/alerting_rules.yml', 'NotificationChannels': 'Configured in Alertmanager for email, Slack, and PagerDuty', 'DashboardProvisioning': 'Automated via Infrastructure as Code (Terraform)'}}]

